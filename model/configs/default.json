{
  "exec_loc": {"type": "str",
    "required": true,
    "help": "System on which code is run: cluster or local."},
  "num_gpu": {"type": "int",
    "required": true,
    "help": "Number of gpu devices available for the execution."},

  "save_checkpoints_secs": {"type": "int",
    "help": "Int determining the frequency at which checkpoints are made and evaluation is run. Either this or checkpoint_freq_epochs has to be specified."},
  "checkpoint_freq_epochs": {"type": "float",
    "help": "Float determining after how many full training epochs checkpoints are made and evaluation is run. Either this or save_checkpoints_secs has to be specified."},

  "delta_t_mean": {"type": "float",
    "help": "If specified this value is subtracted from every dt value."},
  "delta_t_std": {"type": "float",
    "help": "If specified this every dt value is divided by this value."},
  "predictor_s3_input_path": {"type": "str",
    "help": "If `predictor_s3_output_path` and `predictor_batch_size` provided specifies the s3 path whose children are named after vars the model is expecting as input for post-training prediction."},
  "predictor_s3_output_path": {"type": "str",
    "help":"If `predictor_s3_input_path` and `predictor_batch_size` provided specifies the s3 path to populate with predictions generated during post-training prediction."},
  "predictor_batch_size": {"type": "int",
    "help": "If `predictor_s3_input_path` and `predictor_s3_output_path` set specifies the batch size used for post-training prediction."},
  "user_embedding_device": {"type": "str",
    "help": "If provided user embeddings and derivatives stored on the specified device"},
  "use_dynamic_rnn": {"type": "bool",
    "default": true,
    "help": "If true use dynamic_rnn, otherwise use static_rnn."},
  "use_weights": {"type": "bool",
    "default": false,
    "help": "If true use weight the interactions (multiply loss/metrics for the weighted timesteps)."},
  "num_sampled_classes": {"type": "int",
    "default": 5000,
    "help": "Number of classes on which sampled softmax is calculated. If 0 then no sampling is performed."},
  "dataset": {"type": "str",
    "default": "lastfm_10_pc",
    "help": "Name of the dataset: currently lastfm_10_pc and ml-10m."},
  "train_batch_size": {"type": "int",
    "default": 100,
    "help": "Size of one batch processed by 1 or more devices."},
  "validation_batch_size": {"type": "int",
    "default": 100,
    "help": "Size of one batch processed by 1 or more devices."},
  "num_units": {"type": "int",
    "default": 200,
    "help": "Width of the model."},
  "model_id": {"type": "int",
    "default": 1,
    "help": "Number from 0 to 7 representing the combination of modifications to the equations."},
  "model_path": {"type": "str",
    "help": "Provide if want to load checkpointed model - should contain all artifacts created by tensorflow."},
  "model_dir": {"type":  "str",
    "help": "Sagemaker argument specifying the location of all artifacts created by tensorflow. Overwrites model_path, execution_date and folder_naming_vars."
  },
  "sagemaker_data_root": {"type":  "str",
    "help": "Sagemaker argument specifying the location of the folder containing all the datasets."
  },
  "num_users": {"type": "int",
    "help": "Sagemaker argument specifying number of users in the dataset."},
  "num_items": {"type": "int",
    "help": "Sagemaker argument specifying number of items in the dataset."},
  "num_samples": {"type": "lambda x: {y.split(\"=\")[0]: int(y.split(\"=\")[1])  for y in x.split(\",\")}",
    "help": "Sagemaker argument specifying a dict with keys: train, validation, test each specifying the number of samples in the subset. Known issue that using PyCharm Run breaks this when specified."},

  "k_at_prediction": {"type": "int",
    "help": "Specify if number of items returned during inference is different from k. Does not affect training."},
  "last_prediction_only": {"type": "bool",
    "default": false,
    "help": "If true predictions only made for the last timestep specified by seq_lens."},
  "prediction_include_uid": {"type": "bool",
    "default": false,
    "help": "If true includes user_ids in addition to the recommendations in for PREDICT."},
  "key_metrics": {"nargs": "*",
    "default": ["mrr"],
    "help": "Metrics for which exporters are created. The first metric is also used for early stopping."},
  "profiler_hook": {"type": "bool",
    "default": false,
    "help": "If true creates a hook that creates a chrome tracing format of training every 10 steps."},
  "execution_date": {"type": "str",
    "help": "Date of execution of the calling script as opposed to date of execution of the python script."},
  "folder_naming_vars": {"nargs": "*",
    "default": ["args.dataset", "args.num_units"],
    "help": "Matrices for which the regularization term is calculated."},
  "clear_checkpoints": {"type": "bool",
    "default": false,
    "help": "If true checks model_dir and removes all checkpoints and graph.pbtxt from it to conserve disk space."},
  "tf_random_seed": {"type": "int",
    "help": "If provided then training is run under a specific seed."},
  "input_data_format": {"type": "str",
    "default": "tfrecords",
    "help": "Specify the file format to use as input. Currently supporting 'npy' and 'tfrecords'."},
  "use_exporter": {"type": "bool",
    "default": false,
    "help": "If true performs exporting of the model during training (specified in code as via BestExporter)."},
  "zero_loss": {"type": "bool",
    "default": true,
    "help": "If True loss is replaced with constant value of 0. This should be done in case of a large model that doesn't fit into memory."},
  "early_stopping": {"type": "bool",
    "default": true,
    "help": "If True early stopping is activated with metric specified by `key_metrics[0]`."},
  "overwrite": {"type": "bool",
    "default": false,
    "help": "If True simple test case values are used instead of user provided params."},
  "final_eval_multiple_models": {"type": "bool",
    "default": false,
    "help": "If True estimator_utils.evaluate_multiple_checkpoints is called."},
  "metadata_hook_saving_frequency": {"type": "int",
    "help": "If set add estimator_utils.MetadataHook to training with specified logging frequency."},
  "debug_dump_path": {"type": "str",
    "help": "If specified runs in debugging mode and saves intermediary results to specified folder."},
  "debug": {"type": "bool",
    "default": false,
    "help": "Enable online debugger."},
  "tensorboard_debug_address": {"type": "str",
    "help": "Connect to the TensorBoard Debugger Plugin backend specified by the gRPC address (e.g., localhost:1234)"},
  "report_tensor_allocation_upon_oom": {"type": "bool",
    "default": false,
    "help": "Bool determining whether to dump the wall of tensor allocation to stdout if oom."},
  "variable_strategy_CPU": {"type": "bool",
    "default": false,
    "help": "Bool determining whether variables are placed on CPU (True) or GPU (False)."},
  "max_train_epochs_without_improvement": {"type": "float",
    "default": 1.0,
    "help": "Float by which we multiply the number of steps per training epoch - determines threshold for early stopping."},
  "keep_checkpoint_max": {"type": "int",
    "default": 3,
    "help": "Int - count of how many last checkpoints to maintain during training."},
  "train_epochs_without_stopping": {"type": "int",
    "default": 2,
    "help": "Int by which we multiply the number of steps per training - determines when early stopping starts logging."},
  "eval_pc_during_train": {"type": "float",
    "default": 1.0,
    "help": "Float determining the percentage size of evaluation set ran multiple times during training. Between 0 and 1."},
  "timesteps": {"type": "int",
    "default": 20,
    "help": "Int determining the depth of the model in time."},
  "log_device_placement": {"type": "bool",
    "default": false,
    "help": "Bool determining whether log and print all device placement. Produces a lot of text."},
  "learning_rate": {"type": "float",
    "default": 0.001,
    "help": "Fixed learning rate of the model."},
  "time_keep_prob": {"type": "float",
    "default": 1,
    "help": "Probability of any component in the time embedding to be kept during Dropout."},
  "item_keep_prob": {"type": "float",
    "default": 0.8,
    "help": "Probability of any component in the item embedding to be kept during Dropout."},
  "user_keep_prob": {"type": "float",
    "default": 0.5,
    "help": "Probability of any component in the user embedding to be kept during Dropout."},
  "num_epochs": {"type": "float",
    "default": 10,
    "help": "Number of epochs until the training is stopped."},
  "user_reg_weight": {"type": "float",
    "default": 0.01,
    "help": "Regularisation factor for L2 regularisation of certain matrices."},
  "user_related_weights": {"type": "list",
    "default": ["user_gate_u_weight", "update_vector_u_weight"],
    "help": "Matrices for which the regularization term is calculated."},
  "regularize_all": {"type": "bool",
    "default": false,
    "help": "If true user_related_weights are ignored and regularization is applied to all trainable variables."},
  "data_dir_path": {"type": "str",
    "default": "/home/nfs/nknyazev/thesis/data",
    "help": "Location of the input files for all datasets. (Gets replaced during initialisation based on exec_loc)"},
  "log_dir_path": {"type": "str",
    "default": "/home/nfs/nknyazev/thesis/logs",
    "help": "Location of the outputs for the runs. (Gets replaced during initialisation based on exec_loc)"},
  "initializer_range": {"type": "float",
    "default": 0.1,
    "help": "The absolute value of the initialiser bounds."},
  "k": {"type": "int",
    "default": 20,
    "help": "Upper bound for which metrics are calculated e.g. recall@k, mrr@k."},
  "shuffle_train": {"type": "float",
    "help": "Float determining how much to shuffle the subsequences during training. If not provided no shuffle."},
  "shuffle_test": {"type": "float",
    "help": "Float determining how much to shuffle the subsequences during val/test. If not provided no shuffle."},
  "allow_soft_placement": {"type": "bool",
    "default": true,
    "help": "Bool determining whether to allow tensorflow to smartly assign operations/tensors to devices."},
  "store_big_matrices_on_cpu": {"type": "bool",
    "default": true,
    "help": "DEPRECATED. Bool determining whether to store large matrices on cpu instead of allowing them to be on gpu."},
  "place_cell_vars_on_cpu": {"type": "bool",
    "default": false,
    "help": "Bool determining whether to store cell matrices on cpu instead of keeping them to be on gpu."},
  "time_embedding_depth": {"type": "int",
    "default": 1,
    "help": "Number of nonlin(Wx+b) that delta_t goes through before we get the final time embedding."},
  "time_non_lin_fun": {"type": "str",
    "default": "tf.sigmoid",
    "help": "Nonlinear function that is used to obtain the time embedding. Eval'd at runtime."},
  "trainable_zero_state": {"type": "bool",
    "default": false,
    "help": "Bool determining whether the zero state can be trained or it is assumed to be always zeros."},
  "recurrent_dropout": {"type": "bool",
    "default": false,
    "help": "Bool determining whether to use recurrent Dropout or use normal Dropout."},
  "standardise_d_t": {"type": "bool",
    "default": false,
    "help": "Bool determining whether to standarise delta_t at runtime."},
  "cell_type": {"type": "str",
    "default": "TimeDeltaCell",
    "help": "GRU cell object type. Must be imported in estimator_model."},
  "cpu_profiling_freq": {"type": "float",
    "help": "If specified, a process will run in a separate thread printing the CPU usage every `cpu_profiling_freq` seconds."},
  "gpu_profiling_freq": {"type": "float",
    "help": "If specified, a process will run in a separate thread printing the GPU usage every `gpu_profiling_freq` seconds."},
  "cpu_profiling_delay": {"type": "float",
    "help": "If specified and cpu profiling is on, start profiling `cpu_profiling_delay` seconds after the script starts."},
  "gpu_profiling_delay": {"type": "float",
    "help": "If specified and gpu profiling is on, start profiling `gpu_profiling_delay` seconds after the script starts."},
  "comment": {"nargs": "*",
    "help": "Additional collection of strings of arbitrary length. Allows to denote different submissions to be differentiated from others when examining multiple submissions."},
  "start_delay_secs": {"type": "int",
    "default": 120,
    "help": "Time to wait before evaluating the model for the first time."},
  "delay_evaluation_epochs": {"type": "float",
    "default": 0,
    "help": "Number of epochs to wait before evaluating the model for the first time. Operates via calling estimator.train before train_and_evaluate"}
}